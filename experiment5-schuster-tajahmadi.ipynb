{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "672b9747-087b-4b14-964b-b48fd36a2ee7",
   "metadata": {},
   "source": [
    "## 5. Experiment: From Word Embeddings to Paper Recommendation\n",
    "Done by Kourosh Tajahmadi (kt77) and Marek Schuster (ms2228)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dab90aa-980a-4b84-ba69-cdd5588379ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, count, desc, col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import udf, explode, length, col\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import col, lit, rand\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.feature import Word2Vec, Word2VecModel\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Start Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Text Processing with Spark')\\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7f5435-4ddc-46b7-a6ee-2fe98e2d4f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "\n",
    "# Define the schema for papers\n",
    "papers_schema = StructType([\n",
    "    StructField(\"paper_id\", IntegerType()),\n",
    "    StructField(\"type\", StringType()),\n",
    "    StructField(\"journal\", StringType()),\n",
    "    StructField(\"book_title\", StringType()),\n",
    "    StructField(\"series\", StringType()),\n",
    "    StructField(\"publisher\", StringType()),\n",
    "    StructField(\"pages\", StringType()),\n",
    "    StructField(\"volume\", StringType()),\n",
    "    StructField(\"number\", StringType()),\n",
    "    StructField(\"year\", StringType()),\n",
    "    StructField(\"month\", StringType()),\n",
    "    StructField(\"postedat\", StringType()),\n",
    "    StructField(\"address\", StringType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"abstract\", StringType())\n",
    "])\n",
    "\n",
    "# Load Data\n",
    "papers_df = spark.read.csv('papers.csv', schema=papers_schema)\n",
    "papers_df = papers_df.drop(\"type\", \"journal\", \"book_title\", \"series\", \"publisher\", \"pages\", \"volume\", \"number\", \"year\", \"month\", \"postedat\", \"address\")\n",
    "users_libraries_df = spark.read.text('users_libraries.txt')\n",
    "\n",
    "# Split users_libraries into two columns (user_hash_id and user_library)\n",
    "users_libraries_df = users_libraries_df.select(split(users_libraries_df.value, \";\").alias(\"split_values\"))\n",
    "users_libraries_df = users_libraries_df.select(users_libraries_df.split_values[0].alias(\"user_hash_id\"), users_libraries_df.split_values[1].alias(\"user_library\"))\n",
    "\n",
    "# Convert the user_library from a comma-separated string into an array of paper ids.\n",
    "users_libraries_df = users_libraries_df.withColumn(\"user_library\", split(col(\"user_library\"), \",\\s*\").cast(ArrayType(IntegerType())))\n",
    "\n",
    "# Explode the user_library into a new row for each paper\n",
    "users_libraries_df = users_libraries_df.withColumn(\"paper_id\", explode(col(\"user_library\")))\n",
    "\n",
    "# drop the user_library column\n",
    "users_libraries_df = users_libraries_df.drop(\"user_library\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9362f13b-81db-4510-bbbe-053342aa032e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers:  172079\n",
      "Number of papers:  172079\n"
     ]
    }
   ],
   "source": [
    "#print length of papers_df\n",
    "print(\"Number of papers: \", papers_df.count())\n",
    "# discard 1/100 of the data to make it easier to work with\n",
    "#papers_df = papers_df.sample(False, 0.01, 42)\n",
    "#print length of papers_df\n",
    "print(\"Number of papers: \", papers_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa14f2f3-ccfe-465e-8583-d60ec68c0494",
   "metadata": {},
   "source": [
    "## Exercise 5. 1 (Pre-processing Text for word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49450769-29fa-4dba-ace8-0592cf05d099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|paper_id|               words|\n",
      "+--------+--------------------+\n",
      "|   80546|[the, arbitrarine...|\n",
      "| 5842862|[how, choose, goo...|\n",
      "| 1242600|[how, write, cons...|\n",
      "| 3467077|[defrosting, the,...|\n",
      "|  309395|[why, most, publi...|\n",
      "|  305755|[the, structure, ...|\n",
      "| 6603134|[how, build, moti...|\n",
      "|      99|[collective, dyna...|\n",
      "|  105595|[linked, how, eve...|\n",
      "|  212874|[gene, ontology, ...|\n",
      "|  740681|[usage, patterns,...|\n",
      "|     101|[network, motifs,...|\n",
      "|   99857|[the, strength, w...|\n",
      "| 3614773|[rna, seq, revolu...|\n",
      "|  873540|[pattern, recogni...|\n",
      "| 6434100|[quick, guide, fo...|\n",
      "|  100088|[basic, local, al...|\n",
      "| 1387765|[powerlaw, distri...|\n",
      "|  161814|[the, elements, s...|\n",
      "|  117535|[maximum, likelih...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+--------------------+\n",
      "|paper_id|               words|\n",
      "+--------+--------------------+\n",
      "|   80546|[arbitrari, genet...|\n",
      "| 5842862|[choos, good, sci...|\n",
      "| 1242600|[write, consist, ...|\n",
      "| 3467077|[defrost, digit, ...|\n",
      "|  309395|[publish, researc...|\n",
      "|  305755|[structur, collab...|\n",
      "| 6603134|[build, motiv, re...|\n",
      "|      99|[collect, dynam, ...|\n",
      "|  105595|[link, everyth, c...|\n",
      "|  212874|[gene, ontolog, t...|\n",
      "|  740681|[usag, pattern, c...|\n",
      "|     101|[network, motif, ...|\n",
      "|   99857|[strength, weak, ...|\n",
      "| 3614773|[rna, seq, revolu...|\n",
      "|  873540|[pattern, recogni...|\n",
      "| 6434100|[quick, guid, dev...|\n",
      "|  100088|[basic, local, al...|\n",
      "| 1387765|[powerlaw, distri...|\n",
      "|  161814|[element, statist...|\n",
      "|  117535|[maximum, likelih...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#a)\n",
    "# concatenate title and abstract\n",
    "papers_df = papers_df.withColumn('text', concat_ws(' ', papers_df.title, papers_df.abstract))\n",
    "\n",
    "# tokenize text\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words_raw\", pattern=\"[a-zA-Z-_]+\", gaps=False)\n",
    "papers_df = regexTokenizer.transform(papers_df)\n",
    "# replace '-' and '_' in words\n",
    "remove_chars_udf = udf(lambda words: [word.replace('-', '').replace('_', '') for word in words], ArrayType(StringType()))\n",
    "papers_df = papers_df.withColumn(\"words\", remove_chars_udf(col(\"words_raw\")))\n",
    "papers_df = papers_df.drop(\"title\", \"abstract\", \"text\", \"words_raw\")\n",
    "\n",
    "# filter words with length < 3\n",
    "papers_df_cp = papers_df.withColumn(\"words\", expr(\"filter(words, x -> length(x) >= 3)\"))\n",
    "#b)\n",
    "# remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"words_no_stopw\")\n",
    "papers_df = remover.transform(papers_df)\n",
    "#c)\n",
    "# stem words\n",
    "stemmer = PorterStemmer()\n",
    "stemmer_udf = udf(lambda words: [stemmer.stem(word) for word in words], ArrayType(StringType()))\n",
    "papers_df_ip = papers_df.withColumn(\"terms_raw\", stemmer_udf(col(\"words_no_stopw\")))\n",
    "papers_df_ip = papers_df_ip.drop(\"words\", \"words_no_stopw\")\n",
    "papers_df_ip = papers_df_ip.withColumnRenamed(\"terms_raw\", \"words\")\n",
    "\n",
    "\n",
    "# get total number of papers\n",
    "total_papers = papers_df.count()\n",
    "\n",
    "papers_df_cp.show()\n",
    "papers_df_ip.show()\n",
    "papers_df_ip.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3003c9fb-97fc-46d3-a4b7-cc63b2862820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize word2Vec\n",
    "w2v_cp = Word2Vec(vectorSize=100, inputCol=\"words\", outputCol=\"w2v_cp\")\n",
    "w2v_ip = Word2Vec(vectorSize=100, inputCol=\"words\", outputCol=\"w2v_ip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b37deea1-b930-49ca-ae58-6fe604de86b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "model_cp = w2v_cp.fit(papers_df_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc74535d-c3f7-41e9-b40b-36f575b889a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ip = w2v_ip.fit(papers_df_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ccacded-26c2-4b60-8849-539e9ec13342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_cp.write().overwrite().save(\"trainedmodels/cp\")\n",
    "model_ip.write().overwrite().save(\"trainedmodels/ip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae1f20ae-b574-4f40-b5c9-454b8cb59384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_cp = Word2VecModel.load('trainedmodels/cp')    \n",
    "model_ip = Word2VecModel.load('trainedmodels/ip')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "243ee078-29ab-408d-af79-578d003990b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|          word|similarity|\n",
      "+--------------+----------+\n",
      "|  anthropology|   0.83369|\n",
      "|   primatology|   0.83268|\n",
      "|   mathematics|   0.81499|\n",
      "|     sociology|   0.81020|\n",
      "|          arts|   0.80245|\n",
      "|        majors|   0.80226|\n",
      "|    humanities|   0.79825|\n",
      "|       fiction|   0.78621|\n",
      "|historiography|   0.78338|\n",
      "|    philosophy|   0.77431|\n",
      "+--------------+----------+\n",
      "\n",
      "+--------------+----------+\n",
      "|          word|similarity|\n",
      "+--------------+----------+\n",
      "|     scientist|   0.76712|\n",
      "|      sociolog|   0.74283|\n",
      "|    primatolog|   0.73418|\n",
      "|historiographi|   0.72510|\n",
      "|     disciplin|   0.72313|\n",
      "|      humanist|   0.70463|\n",
      "|   anthropolog|   0.70277|\n",
      "|      scientif|   0.70142|\n",
      "|    philosophi|   0.68934|\n",
      "|        anarch|   0.68238|\n",
      "+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number as fmt\n",
    "# Use build in function of the Model to find most similar synonyms\n",
    "model_cp.findSynonyms(\"science\", 10).select(\"word\", fmt(\"similarity\", 5).alias(\"similarity\")).show()\n",
    "model_ip.findSynonyms(stemmer.stem(\"science\"), 10).select(\"word\", fmt(\"similarity\", 5).alias(\"similarity\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c714173-f67d-4372-9b7e-ab44d7012e6b",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "Our results show that the consvervative pre-processing shows better results for finding the most similar words, which is quite unexpected. We tought that the stemming would lead to words being more similar to each other. Overall the results seem a bit off, but since the trainig portion of the exercise is very easy with little room for change, and also us not finding any errors in our pre-processing, we cannot point to the reason for this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50005a00-19bc-4b4c-a91c-029f84309cad",
   "metadata": {},
   "source": [
    "## 5.2 Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d28ce263-48f3-4e29-ac31-2fa4a02077ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def analogy(word1, word2, word3, model, stemming=False):\n",
    "    raw_words = [word1, word2, word3]\n",
    "    words = []\n",
    "    vectors = model.getVectors()\n",
    "    words_as_vectors = []\n",
    "    for i in raw_words:\n",
    "        words.append([x.lower().strip() for x in re.split(\"[^A-Za-z]+\", i)])\n",
    "        \n",
    "    if stemming:\n",
    "        for i, wordlist in enumerate(words):\n",
    "            for j, word in enumerate(wordlist):\n",
    "                words[i][j] = stemmer.stem(word)\n",
    "        \n",
    "    for word in words:\n",
    "        if len(word) > 1:\n",
    "            tmp = spark.createDataFrame([[word]], [\"words\"])\n",
    "            average = model.transform(tmp)\n",
    "            words_as_vectors.append(average.head()[1])\n",
    "        else:\n",
    "            words_as_vectors.append(vectors.where(vectors.word==word[0]).head()[1])\n",
    "        \n",
    "    w = words_as_vectors[0] - words_as_vectors[1] + words_as_vectors[2]\n",
    "    result = model.findSynonyms(w, 5)\n",
    "    best = \"\"\n",
    "    array = np.array(result.select(\"word\").collect())\n",
    "\n",
    "    for x in array:\n",
    "        if x[0] not in [j for i in words for j in i]:\n",
    "            best = x[0]\n",
    "            break\n",
    "    \n",
    "    return best, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee692d06-ecbd-4fe0-a4b2-0d3c38911ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|         word|        similarity|\n",
      "+-------------+------------------+\n",
      "|   hypermedia|0.7217651009559631|\n",
      "|  intelligent|0.7086201310157776|\n",
      "|      machine|0.6683545112609863|\n",
      "|     tutoring| 0.661483645439148|\n",
      "|collaborative|0.6565461754798889|\n",
      "+-------------+------------------+\n",
      "\n",
      "hypermedia\n",
      "+------------+------------------+\n",
      "|        word|        similarity|\n",
      "+------------+------------------+\n",
      "|      machin|  0.68124920129776|\n",
      "|  overcommit|0.6691328883171082|\n",
      "|studentcentr|0.6606923937797546|\n",
      "|    groupwar|0.6340607404708862|\n",
      "|        lmss|0.6320806741714478|\n",
      "+------------+------------------+\n",
      "\n",
      "overcommit\n"
     ]
    }
   ],
   "source": [
    "word, df = analogy(\"machine learning\", \"predictions\", \"recommender systems\", model_cp)\n",
    "df.show()\n",
    "print(word)\n",
    "word, df = analogy(\"machine learning\", \"predictions\", \"recommender systems\", model_ip, True)\n",
    "df.show()\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e9597-99e2-46c9-92ae-72e76028bcfc",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "It is hard to evaluate which model performed better as both of them do not give intuitive results fitting our analogy.\n",
    "\n",
    "We see that the requirment \"Do not allow any of the words passed as arguments or the tokens of\n",
    "which these are composed to be returned as w, i.e. w not in {machine, learning, predictions,recommender,systems}\n",
    "in the previous example\" is fulfilled, as the ip model actually predicts the word \"machin\" to be the best solution for the analogy,\n",
    "but it is not returned as w, because it is already contained in \"machine learning\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ab3c6-ba55-4a58-bdc0-28c30f9d9847",
   "metadata": {},
   "source": [
    "## 5.3 From Embeddings to Paper Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55af386-88b5-4e78-b1a3-6a3b6083c751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors, _convert_to_vector\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.linalg import DenseVector, VectorUDT\n",
    "\n",
    "def cosine_similarity(user_profiles_df, item_profiles_df, user_col='user_hash_id', user_profiles_col='user_profile', item_col='paper_id', item_profiles_col='embedding_profile'):\n",
    "    \"\"\"\n",
    "    Compute cosine similarities between user profiles and item profiles.\n",
    "\n",
    "    user_profiles_df: dataframe of user profiles with user_col and user_profiles_col\n",
    "    item_profiles_df: dataframe of item profiles with item_col and item_profiles_col\n",
    "\n",
    "    Returns: dataframe of user-item pairs and their cosine similarities\n",
    "    \"\"\"\n",
    "\n",
    "    # A UDF to compute dot product of two vectors\n",
    "    dot_product = udf(lambda v1, v2: float(v1.dot(v2)), DoubleType())\n",
    "    # A UDF to compute the norm of a vector\n",
    "    norm = udf(lambda v: float(v.norm(2)), DoubleType())\n",
    "\n",
    "    # Add a new column to store vector norm\n",
    "    user_profiles_df = user_profiles_df.withColumn(user_profiles_col+'_norm', norm(col(user_profiles_col)))\n",
    "    item_profiles_df = item_profiles_df.withColumn(item_profiles_col+'_norm', norm(col(item_profiles_col)))\n",
    "\n",
    "    # Cross join the dataframes to get all combinations of user-item pairs\n",
    "    cross_df = user_profiles_df.crossJoin(item_profiles_df)\n",
    "\n",
    "    # Compute dot product of the vectors\n",
    "    cross_df = cross_df.withColumn('dot', dot_product(col(user_profiles_col), col(item_profiles_col)))\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cross_df = cross_df.withColumn('cosine_similarity', col('dot') / (col(user_profiles_col+'_norm') * col(item_profiles_col+'_norm')))\n",
    "\n",
    "    # Select only necessary columns\n",
    "    result = cross_df.select([user_col, item_col, 'cosine_similarity'])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26e9d26a-7901-4b89-bc55-699aa75887fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number\n",
    "\n",
    "def compute_profiles(user_df, paper_df, model):\n",
    "    # Simply use build in transform function to calculate the paper_profile\n",
    "    paper_profile = model.transform(paper_df)\n",
    "    paper_profile = paper_profile.select(\"paper_id\", col(\"w2v_cp\").alias(\"embedding_profile\"))\n",
    "    \n",
    "    # Join users with pre-processed paper_df to get dataframe of users and the list of words in papers they like\n",
    "    # then apply map_reduce to make it just one row per user with one long list of words\n",
    "    # Finally transform this reduced user | words Dataframe using the model to generate user_profile\n",
    "    user_doc_df = user_df.join(paper_df, user_df.paper_id ==  paper_df.paper_id, \"inner\").drop(\"paper_id\").orderBy(\"user_hash_id\")\n",
    "    \n",
    "    user_doc_df_reduced = user_doc_df.rdd.map(lambda user_doc_df: (user_doc_df.user_hash_id, user_doc_df.words)).reduceByKey(lambda a, b: a+b).toDF()\n",
    "    user_doc_df_reduced = user_doc_df_reduced.select(col(\"_1\").alias(\"user_hash_id\"), col(\"_2\").alias(\"words\"))\n",
    "    user_profile = model.transform(user_doc_df_reduced)\n",
    "    \n",
    "    user_profile = user_profile.select(col(\"user_hash_id\"), col(\"words\"), col(\"w2v_cp\").alias(\"user_profile\"))\n",
    "    \n",
    "    return user_profile, paper_profile\n",
    "    \n",
    "\n",
    "def w2vRS(user_df, paper_df, model, k, user_id=None):\n",
    "    \n",
    "    user_profile, paper_profile = compute_profiles(user_df, paper_df, model)\n",
    "    \n",
    "    # Use function from excercise 3 to calculate cosine_similarity\n",
    "    cs_df = cosine_similarity(user_profile, paper_profile)\n",
    "    \n",
    "    # If a User was specified remoce all other users from the Dataframe\n",
    "    if(user_id != None):\n",
    "        cs_df = cs_df.filter(cs_df.user_hash_id == user_id)\n",
    "    \n",
    "    # use window function to sort the Dataframe and put a column that indicates the rows rank    \n",
    "    window = Window.partitionBy(\"user_hash_id\").orderBy(col(\"cosine_similarity\").desc())\n",
    "    \n",
    "    cs_df=cs_df.withColumn(\"top_k\",row_number().over(window))\n",
    "    \n",
    "    # use that rank to only give top-k recommendations\n",
    "    cs_df = cs_df.filter(col(\"top_k\") <= k)\n",
    "    \n",
    "    return cs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c8ece-3439-489b-be2b-5ed1d21ca05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = w2vRS(users_libraries_df, papers_df_cp, model_cp, 10, user_id=\"1eac022a97d683eace8815545ce3153f\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fa238d-8142-4801-b32d-4493e794627a",
   "metadata": {},
   "source": [
    "## 5.4 (Evaluation of Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39759df6-c7db-4945-b37b-945457354b69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from pyspark.sql.functions import rank, col\n",
    "from pyspark.sql.functions import udf, array, lit\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "\n",
    "from pyspark.sql.functions import slice\n",
    "import math\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "\n",
    "# UDF for computing precision\n",
    "def precision_at_k(test_set, top_k_recommendations):\n",
    "    num_hits = len(set(top_k_recommendations).intersection(set(test_set)))\n",
    "    return float(num_hits) / len(top_k_recommendations)\n",
    "# UDF for computing recall\n",
    "def recall_at_k(test_set, top_k_recommendations):\n",
    "    num_hits = len(set(top_k_recommendations).intersection(set(test_set)))\n",
    "    return float(num_hits) / len(test_set)\n",
    "# UDF for computing MRR\n",
    "def mrr_at_k(test_set, top_k_recommendations):\n",
    "    mrr_value = 0.0\n",
    "    for i, rec in enumerate(top_k_recommendations):\n",
    "        if rec in test_set:\n",
    "            mrr_value = 1.0 / (i + 1)\n",
    "            break\n",
    "    return mrr_value\n",
    "# UDF for computing NDCG\n",
    "def ndcg_at_k(test_set, top_k_recommendations):\n",
    "    dcg = 0\n",
    "    idcg = 0\n",
    "    for i, rec in enumerate(top_k_recommendations):\n",
    "        if rec in test_set:\n",
    "            dcg += 1 / math.log2(i + 2)  # i + 2 because log index starts at 1, not 0 and the positions are 1-based\n",
    "    sorted_test_set = sorted(test_set, reverse=True)\n",
    "    for i in range(min(len(sorted_test_set), len(top_k_recommendations))):\n",
    "        idcg += 1 / math.log2(i + 2)\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "precision_udf = udf(precision_at_k, FloatType())\n",
    "recall_udf = udf(recall_at_k, FloatType())\n",
    "mrr_udf = udf(mrr_at_k, FloatType())\n",
    "ndcg_udf = udf(ndcg_at_k, DoubleType())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(df, k):\n",
    "\n",
    "    # Slice the top k recommendations from the recommendations list and compute evaluation metrics\n",
    "    df = df.withColumn('top_k_recommendations', slice(df['recommendations'], 1, k))\n",
    "    df = df.withColumn('precision_at_k', precision_udf(df['test_set'], df['top_k_recommendations']))\n",
    "    df = df.withColumn('recall_at_k', recall_udf(df['test_set'], df['top_k_recommendations']))\n",
    "    df = df.withColumn('mrr_at_k', mrr_udf(df['test_set'], df['top_k_recommendations']))\n",
    "    df = df.withColumn('ndcg_at_k', ndcg_udf(df['test_set'], df['top_k_recommendations']))\n",
    "\n",
    "    # Compute average precision@k, recall@k, and MRR@k\n",
    "    avg_precision_at_k = df.select(avg(df['precision_at_k'])).collect()[0][0]\n",
    "    avg_recall_at_k = df.select(avg(df['recall_at_k'])).collect()[0][0]\n",
    "    avg_mrr_at_k = df.select(avg(df['mrr_at_k'])).collect()[0][0]\n",
    "    avg_ndcg_at_k = df.agg(avg(col('ndcg_at_k'))).collect()[0][0]\n",
    "\n",
    "\n",
    "    # Change this line to check for zeros instead of null\n",
    "    proportion_zero_mrr = df.where(df['mrr_at_k'] == 0).count() / df.count()\n",
    "\n",
    "    print(f\"Average Precision@{k}: {avg_precision_at_k}, Average Recall@{k}: {avg_recall_at_k}, Average MRR@{k}: {avg_mrr_at_k}, Proportion of MRR zero@{k}: {proportion_zero_mrr},  Average NDCG@{k}: {avg_ndcg_at_k}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6d0d282-6114-4a26-9059-904c203eeb06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rand, row_number\n",
    "\n",
    "def sample_and_split_per_user(users_libraries_df, paper_df, n=50, min_items=5):\n",
    "    \"\"\"\n",
    "    Randomly select n users with at least 5 items in their libraries, split their libraries into training and test sets per user, and compute their profiles.\n",
    "\n",
    "    users_libraries_df: dataframe of users and their libraries\n",
    "    paper_df: dataframe of papers and their words\n",
    "    n: number of users to sample\n",
    "    min_items: minimum number of items in a user's library\n",
    "\n",
    "    Returns:\n",
    "        training_df: a dataframe containing the training set papers for each user\n",
    "        test_df: a dataframe containing the test set papers for each user\n",
    "    \"\"\"\n",
    "    # Count the number of items in each user's library\n",
    "    user_counts = users_libraries_df.groupBy('user_hash_id').count()\n",
    "\n",
    "    # Select users with at least min_items(default 10) items\n",
    "    # This extra step is to ensure that users have enough items to split into training and test sets\n",
    "    users_with_5_items = user_counts.filter(col('count') >= min_items)\n",
    "\n",
    "    # Randomly select n distinct users from this filtered group\n",
    "    sampled_users = users_with_5_items.orderBy(rand()).limit(n)\n",
    "\n",
    "    # Join with the original dataframe to get the entries for these users only\n",
    "    sampled_users_df = sampled_users.join(users_libraries_df, \"user_hash_id\")\n",
    "\n",
    "    # Add a column of random numbers and row number per user\n",
    "    window = Window.partitionBy('user_hash_id').orderBy(rand())\n",
    "    sampled_users_df = sampled_users_df.withColumn('rand', rand()).withColumn('row_num', row_number().over(window))\n",
    "\n",
    "    # Get the maximum row number per user\n",
    "    max_row_num_df = sampled_users_df.groupBy('user_hash_id').max('row_num')\n",
    "    sampled_users_df = sampled_users_df.join(max_row_num_df, \"user_hash_id\")\n",
    "\n",
    "    # Split into training and test dataframes per user based on the random number\n",
    "    training_df = sampled_users_df.filter(col('row_num') <= 0.8 * col('max(row_num)')).drop('rand', 'row_num', 'max(row_num)')\n",
    "    test_df = sampled_users_df.filter(col('row_num') > 0.8 * col('max(row_num)')).drop('rand', 'row_num', 'max(row_num)')\n",
    "\n",
    "    # drop count column from training_df and test_df\n",
    "    training_df = training_df.drop(\"count\")\n",
    "    test_df = test_df.drop(\"count\")\n",
    "\n",
    "    # Compute user profiles based on the training sets\n",
    "    #training_profiles, paper_profiles = compute_profiles(training_df, paper_df, model)\n",
    "\n",
    "    return training_df, test_df #, training_profiles, paper_profiles\n",
    "\n",
    "# Call the function\n",
    "training_df, test_df = sample_and_split_per_user(users_libraries_df, papers_df_cp, min_items=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8fcc5b-9086-449d-8d9c-1e9746718a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------------------+-----+\n",
      "|        user_hash_id|paper_id| cosine_similarity|top_k|\n",
      "+--------------------+--------+------------------+-----+\n",
      "|1f29a9b52672539eb...| 6854433|0.9917092578839937|    1|\n",
      "|1f29a9b52672539eb...| 7068502|0.9915973161344459|    2|\n",
      "|1f29a9b52672539eb...| 8751904|0.9060308507322081|    3|\n",
      "|1f29a9b52672539eb...|  383497| 0.904558015629168|    4|\n",
      "|1f29a9b52672539eb...| 3340317|0.8979698292514435|    5|\n",
      "|1f29a9b52672539eb...|  937992|0.8957776542543118|    6|\n",
      "|1f29a9b52672539eb...| 3861668|0.8934774408064308|    7|\n",
      "|1f29a9b52672539eb...| 6951763|0.8923846608547338|    8|\n",
      "|1f29a9b52672539eb...| 3047357|0.8917680724998116|    9|\n",
      "|1f29a9b52672539eb...|  161261|0.8914947652213865|   10|\n",
      "|1f29a9b52672539eb...|  437141|0.8909900134007812|   11|\n",
      "|1f29a9b52672539eb...| 2968653|0.8908766044932881|   12|\n",
      "|1f29a9b52672539eb...|10540334|0.8907382525528902|   13|\n",
      "|1f29a9b52672539eb...|  431014|0.8868803641484992|   14|\n",
      "|1f29a9b52672539eb...|  910304|0.8857346521079029|   15|\n",
      "|1f29a9b52672539eb...| 3192432|0.8832922565214804|   16|\n",
      "|1f29a9b52672539eb...| 7205936|0.8832215343550159|   17|\n",
      "|1f29a9b52672539eb...| 7412860|0.8822252108762154|   18|\n",
      "|1f29a9b52672539eb...| 1761549|0.8817221547560571|   19|\n",
      "|1f29a9b52672539eb...|  530837|0.8807955693406323|   20|\n",
      "+--------------------+--------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_training = w2vRS(training_df, papers_df_cp, model_cp, 30)\n",
    "result_training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44fcdc90-8e9e-4ae7-8c11-d86d59fba083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    " \n",
    "result_training_reduced = result_training.groupBy(\"user_hash_id\").agg(collect_list(\"paper_id\").alias(\"recommendations\"))\n",
    "test_set_df = test_df.groupBy(\"user_hash_id\").agg(collect_list(\"paper_id\").alias(\"test_set\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3277f75b-90bf-4034-9f6d-5aaaa2a1cc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|        user_hash_id|     recommendations|            test_set|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|1f29a9b52672539eb...|[6854433, 7068502...|           [4401985]|\n",
      "|23191d8c18ff3c36e...|[9452968, 6960437...|[919241, 1279901,...|\n",
      "|5915bcf11c8221ff7...|[423554, 5983055,...|    [366651, 405057]|\n",
      "|5e1cec216680e931b...|[828974, 8266941,...|[141092, 1082836,...|\n",
      "|79c45160c1c27a72c...|[1295217, 1255620...|[6829534, 6829487...|\n",
      "|a2154466ea49dbffd...|[3467770, 1144333...|[637513, 782670, ...|\n",
      "|a6ec425f49ccda07d...|[586862, 1079175,...|             [56516]|\n",
      "|d3ed55d6afe5effc4...|[8977504, 555091,...|            [347169]|\n",
      "|d6fa3fd987a1e0103...|[3365601, 6641683...|           [6641668]|\n",
      "|df130214ee66bba5e...|[1368783, 2362311...|[5842862, 2491624...|\n",
      "|fad932e21bee6a37b...|[334659, 4781936,...|    [167212, 583887]|\n",
      "|0baa797ec9383cf73...|[2431278, 8632966...|[6663788, 4166879...|\n",
      "|2ecfc0306113183a6...|[4008490, 4537934...|[1339049, 6207269...|\n",
      "|348065432892350cb...|[507565, 4742920,...|  [6626686, 4051166]|\n",
      "|38950a23f71beef0d...|[5818453, 3702730...|           [6040601]|\n",
      "|453e87c3dec542289...|[1059458, 180066,...|[296774, 222637, ...|\n",
      "|787447959ff46fdfc...|[840633, 3935245,...|[572256, 402286, ...|\n",
      "|a3c65b2ed869ddf3a...|[6940990, 7118382...|           [6101087]|\n",
      "|c41b3f03048e50f04...|[8121383, 9598113...|[8493345, 9433226...|\n",
      "|c9abb771c493ec213...|[2404696, 821592,...|  [4234351, 6694574]|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = result_training_reduced.join(test_set_df, (\"user_hash_id\"))\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5b132c0-c3a8-4403-ad87-43e3e884260f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for k = 5\n",
      "Average Precision@5: 0.013043478455232538, Average Recall@5: 0.006184407793309378, Average MRR@5: 0.02898550746233567, Proportion of MRR zero@5: 0.9565217391304348,  Average NDCG@5: 0.015025331090027207\n",
      "Computing metrics for k = 10\n",
      "Average Precision@10: 0.010869565379360447, Average Recall@10: 0.0206771618484155, Average MRR@10: 0.03333333361407985, Proportion of MRR zero@10: 0.9130434782608695,  Average NDCG@10: 0.018627673861905617\n",
      "Computing metrics for k = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 42806)\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_85/667459231.py\", line 5, in <module>\n",
      "    metrics_df = compute_metrics(final_df, k)\n",
      "  File \"/tmp/ipykernel_85/708528552.py\", line 62, in compute_metrics\n",
      "    avg_precision_at_k = df.select(avg(df['precision_at_k'])).collect()[0][0]\n",
      "  File \"/usr/local/spark/python/pyspark/sql/dataframe.py\", line 1216, in collect\n",
      "    sock_info = self._jdf.collectToPython()\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/usr/local/spark/python/pyspark/errors/exceptions/captured.py\", line 169, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing metrics for k = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 62\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(df, k)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Compute average precision@k, recall@k, and MRR@k\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m avg_precision_at_k \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mavg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision_at_k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     63\u001b[0m avg_recall_at_k \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect(avg(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall_at_k\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:1216\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1216\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(111, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2116\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2113\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m   2114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2116\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_showtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[1;32m   2118\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[1;32m   2119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py:550\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    544\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    545\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    547\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m\"\u001b[39m: stb,\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    551\u001b[0m }\n\u001b[1;32m    553\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[1;32m    554\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:471\u001b[0m, in \u001b[0;36mPy4JJavaError.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    470\u001b[0m     gateway_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_exception\u001b[38;5;241m.\u001b[39m_gateway_client\n\u001b[0;32m--> 471\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m get_return_value(answer, gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "for k in [5, 10, 30]:\n",
    "    print(f\"Computing metrics for k = {k}\")\n",
    "    \n",
    "    metrics_df = compute_metrics(final_df, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd6540cc-e64a-487a-9fd7-b1cb970f3aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for k = 5\n",
      "Average Precision@5: 0.028000000417232513, Average Recall@5: 0.013291700817644596, Average MRR@5: 0.05300000011920929, Proportion of MRR zero@5: 0.86,  Average NDCG@5: 0.025075233491218932\n",
      "Computing metrics for k = 10\n",
      "Average Precision@10: 0.01600000023841858, Average Recall@10: 0.014125034175813199, Average MRR@10: 0.05500000014901161, Proportion of MRR zero@10: 0.84,  Average NDCG@10: 0.020526588763331563\n",
      "Computing metrics for k = 30\n",
      "Average Precision@30: 0.017333334237337114, Average Recall@30: 0.04153650015592575, Average MRR@30: 0.06411904819309712, Proportion of MRR zero@30: 0.68,  Average NDCG@30: 0.032365627257366095\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Repeat for min_items = 20\n",
    "training_df, test_df = sample_and_split_per_user(users_libraries_df, papers_df_cp, min_items=20)\n",
    "result_training = w2vRS(training_df, papers_df_cp, model_cp, 30)\n",
    "result_training_reduced = result_training.groupBy(\"user_hash_id\").agg(collect_list(\"paper_id\").alias(\"recommendations\"))\n",
    "test_set_df = test_df.groupBy(\"user_hash_id\").agg(collect_list(\"paper_id\").alias(\"test_set\"))\n",
    "final_df = result_training_reduced.join(test_set_df, (\"user_hash_id\"))\n",
    "\n",
    "for k in [5, 10, 30]:\n",
    "    print(f\"Computing metrics for k = {k}\")\n",
    "    \n",
    "    metrics_df = compute_metrics(final_df, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ba7f6-5015-40da-ba1a-593a3a710e81",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "min_items = 0\n",
    "\n",
    "Computing metrics for k = 5\n",
    "-> Average Precision@5: 0.013043478455232538, Average Recall@5: 0.006184407793309378, Average MRR@5: 0.02898550746233567, Proportion of MRR zero@5: 0.9565217391304348,  Average NDCG@5: 0.015025331090027207\n",
    "\n",
    "Computing metrics for k = 10\n",
    "-> Average Precision@10: 0.010869565379360447, Average Recall@10: 0.0206771618484155, Average MRR@10: 0.03333333361407985, Proportion of MRR zero@10: 0.9130434782608695,  Average NDCG@10: 0.018627673861905617\n",
    "\n",
    "Computing metrics for k = 30\n",
    "-> Average Precision@30: 0.008888889269696342, Average Recall@30: 0.08902003264261617, Average MRR@30: 0.06835978875557581, Proportion of MRR zero@30: 0.8,  Average NDCG@30: 0.06529070753763205\n",
    "\n",
    "mit_items = 20\n",
    "\n",
    "Computing metrics for k = 5\n",
    "Average Precision@5: 0.028000000417232513, Average Recall@5: 0.013291700817644596, Average MRR@5: 0.05300000011920929, Proportion of MRR zero@5: 0.86,  Average NDCG@5: 0.025075233491218932\n",
    "\n",
    "Computing metrics for k = 10\n",
    "Average Precision@10: 0.01600000023841858, Average Recall@10: 0.014125034175813199, Average MRR@10: 0.05500000014901161, Proportion of MRR zero@10: 0.84,  Average NDCG@10: 0.020526588763331563\n",
    "\n",
    "Computing metrics for k = 30\n",
    "Average Precision@30: 0.017333334237337114, Average Recall@30: 0.04153650015592575, Average MRR@30: 0.06411904819309712, Proportion of MRR zero@30: 0.68,  Average NDCG@30: 0.032365627257366095\n",
    "\n",
    "\n",
    "\n",
    "The NDCG increased noticably for the higher paper minimum, indicating that more meaningful recommendations where achieved this way as there were more of them already present in the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
